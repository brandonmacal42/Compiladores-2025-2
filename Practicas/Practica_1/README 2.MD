# Pr√°ctica 1: Expresiones Regulares y Lexers

Este proyecto implementa un sistema para identificar patrones en cadenas de texto utilizando **aut√≥matas finitos** y expresiones regulares.

## 1Ô∏è‚É£ Clase `Automata` (Aut√≥mata Finito)

Esta clase representa un aut√≥mata finito que puede ser **determinista o no determinista**.  
 Su objetivo es reconocer cadenas que pertenezcan a un lenguaje definido por un conjunto de reglas de transici√≥n.

- `states`: Conjunto de estados posibles del aut√≥mata.
- `initial`: Estado inicial desde donde empieza el an√°lisis.
- `final`: Conjunto de estados finales (aceptaci√≥n).
- `transitions`: Un diccionario que indica c√≥mo cambia el estado del aut√≥mata seg√∫n el s√≠mbolo de entrada.

### üõ†Ô∏è M√©todos

#### üîπ `accepts(cadena: str) -> bool`

- Verifica si una cadena es aceptada por el aut√≥mata.
- **Recorre** la cadena de entrada y cambia de estado seg√∫n las transiciones definidas.
- Si el estado final es parte del conjunto de estados de aceptaci√≥n, **retorna `True`**, de lo contrario, **retorna `False`**.

#### üîπ `match_token(texto: str) -> list`

- Encuentra **todos los tokens v√°lidos** en el texto que sean reconocidos por el aut√≥mata.
- Recorre el texto y almacena las posiciones `(inicio, fin)` de los fragmentos que sean aceptados por el aut√≥mata.

---

## 2Ô∏è‚É£ Funci√≥n `compile(regex: str) -> Automata`

- Construye un aut√≥mata a partir de una **expresi√≥n regular**.
- **Debe reconocer** los operadores:
  - `|` (or)
  - `*` (cierre de Kleene)
  - `+` (una o m√°s veces)
  - `?` (cero o una vez)
- **Retorna** un objeto de la clase `Automata` que representa el aut√≥mata generado.

---

## 3Ô∏è‚É£ Pruebas con un Aut√≥mata Generado

Se crea un **aut√≥mata** a partir de la siguiente expresi√≥n regular:

```python
pattern = compile('ni√±a|os?')
```

## 1Ô∏è‚É£ Instalaci√≥n y Requisitos

- Se requiere **Python 3.x** para ejecutar el programa.
- Para verificar la instalaci√≥n de Python:
  ```bash
  python3 --version
  ```

---

## 2Ô∏è‚É£ Ejecuci√≥n del Programa

### a. Ejecutar el archivo principal

- Desde la terminal, dentro del directorio donde est√° `practica1_compiladores.py`:
  ```bash
  python3 practica1_compiladores.py
  ```
- Esto ejecutar√° las pruebas del aut√≥mata y mostrar√° los resultados en la consola.

### b. Importar en otro script

- Para usar el aut√≥mata en otro archivo Python:

  ```python
  from automata import compile, tokenize

  pattern = compile('ni√±a|os?')
  print(pattern.accepts('ni√±a'))  # True
  print(pattern.match_token('El ni√±o y la ni√±a juegan.'))
  ```

- Esto permite construir aut√≥matas personalizados y analizarlos en distintas cadenas.

---

## 3Ô∏è‚É£ Posibles Errores y Soluciones

- **Error:** `NameError: name 'tokenize' is not defined`

  - **Causa:** La funci√≥n `tokenize()` no est√° definida o no ha sido importada.
  - **Soluci√≥n:** Aseg√∫rate de que `tokenize` est√° correctamente importado en `practica1_compiladores.py`.

- **Error:** `TypeError: Automata.accepts() missing 1 required positional argument: 'cadena'`
  - **Causa:** El m√©todo `accepts()` no est√° recibiendo un argumento v√°lido.
  - **Soluci√≥n:** Verifica que el aut√≥mata se est√© creando correctamente con `compile(regex)` y que `accepts()` se llame con una cadena v√°lida.

---
